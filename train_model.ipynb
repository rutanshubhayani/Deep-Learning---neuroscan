{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c013f7-2109-48d7-9db5-3a519eb98e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72faaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4bf469-1a0e-45db-b856-093f34f72440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, numpy as np, matplotlib.pyplot as plt, tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "DATA_DIR = \"C:/Users/Admin/Desktop/Deep-Learning---neuroscan/dataset/brain-mri-images-for-brain-tumor-detection\"\n",
    "  \n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED); np.random.seed(SEED); random.seed(SEED)\n",
    "\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8aaa1-f774-4e19-959b-456fb0dac426",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    color_mode=\"grayscale\",      \n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Normalize to [0,1] and prefetch\n",
    "def norm(x, y): return (tf.cast(x, tf.float32) / 255.0, y)\n",
    "train_ds = train_ds.map(norm).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = val_ds.map(norm).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38868ad-7fda-458a-962e-e00b6cb86274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = keras.Input(shape=(*IMG_SIZE, 1))  # (150,150,1)\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', name=\"conv1\")(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', name=\"conv2\")(x)  \n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"tumor_cnn\")\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\"), keras.metrics.Precision(name=\"prec\"), keras.metrics.Recall(name=\"rec\")],\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0598bb5e-04e7-4d2b-aff2-1f6ca80d5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor=\"val_loss\"),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.5, monitor=\"val_loss\"),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151abcf1-da1e-488f-95a5-f861378cb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "plt.figure(); plt.plot(history.history[\"accuracy\"], label=\"train_acc\"); plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\"); plt.legend(); plt.title(\"Accuracy\"); plt.show()\n",
    "plt.figure(); plt.plot(history.history[\"loss\"], label=\"train_loss\"); plt.plot(history.history[\"val_loss\"], label=\"val_loss\"); plt.legend(); plt.title(\"Loss\"); plt.show()\n",
    "\n",
    "# Confusion matrix on validation\n",
    "y_true, y_pred = [], []\n",
    "for xb, yb in val_ds:\n",
    "    p = (model.predict(xb, verbose=0).ravel() > 0.5).astype(int)\n",
    "    y_pred.extend(p.tolist())\n",
    "    y_true.extend(yb.numpy().ravel().astype(int).tolist())\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest'); plt.title(\"Confusion Matrix\"); plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names); plt.yticks(tick_marks, class_names)\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.ylabel('True'); plt.xlabel('Pred'); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec491a72-1741-4cce-8460-fcb9b703c3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "MODEL_PATH = \"models/brain_tumor_model.keras\"  # native Keras format\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Saved:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68fb14f-4a9c-4269-b2fe-d39627a07428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_gradcam_heatmap(model, img_tensor, last_conv_layer_name=\"conv2\"):\n",
    "    # Ensure the model is built (call once)\n",
    "    _ = model(img_tensor, training=False)\n",
    "\n",
    "    conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_out, preds = grad_model(img_tensor, training=False)\n",
    "        # For binary outputs, target the tumor probability (index 0)\n",
    "        loss = preds[:, 0]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_out)                               # (1,H,W,C)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))                # (C,)\n",
    "    conv_out = conv_out[0]                                              # (H,W,C)\n",
    "\n",
    "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_out), axis=-1)\n",
    "    heatmap = tf.maximum(heatmap, 0)                                    # ReLU\n",
    "    max_val = tf.reduce_max(heatmap) + 1e-8\n",
    "    heatmap = heatmap / max_val\n",
    "    return heatmap.numpy()                                              # (H,W)\n",
    "\n",
    "# Grab one batch from val_ds\n",
    "for xb, yb in val_ds.take(1):\n",
    "    # pick an index to visualize\n",
    "    idx = 0\n",
    "    img = xb[idx:idx+1]  # shape (1,150,150,1)\n",
    "    label = int(yb[idx].numpy())\n",
    "    prob = float(model.predict(img, verbose=0)[0][0])\n",
    "    heatmap = get_gradcam_heatmap(model, img, \"conv2\")\n",
    "\n",
    "    # Plot original (grayscale) + heatmap overlay\n",
    "    h = (heatmap * 255).astype(\"uint8\")\n",
    "    h = tf.image.resize(tf.expand_dims(h, -1), IMG_SIZE).numpy().squeeze()  # (150,150)\n",
    "\n",
    "    plt.figure(figsize=(9,4))\n",
    "    plt.subplot(1,3,1); plt.imshow(img[0].numpy().squeeze(), cmap=\"gray\"); plt.title(f\"Original\\nLabel: {class_names[label]}\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,2); plt.imshow(heatmap, cmap=\"jet\"); plt.title(\"Grad-CAM\"); plt.axis(\"off\")\n",
    "    plt.subplot(1,3,3); \n",
    "    plt.imshow(img[0].numpy().squeeze(), cmap=\"gray\")\n",
    "    plt.imshow(h, cmap=\"jet\", alpha=0.4); \n",
    "    plt.title(f\"Overlay\\nPred prob (tumor): {prob:.2f}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566fa35-0877-4381-a2fa-eb7eef62cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "IMG_PATH = \"C:/Users/Admin/Desktop/Deep-Learning---neuroscan/dataset/brain-mri-images-for-brain-tumor-detection/yes/Y1.jpg\"\n",
    "\n",
    "\n",
    "img = Image.open(IMG_PATH).convert(\"L\").resize(IMG_SIZE)\n",
    "arr = np.array(img, dtype=np.float32)/255.0\n",
    "arr = arr[None, ..., None]  # (1,150,150,1)\n",
    "\n",
    "prob = float(model.predict(arr, verbose=0)[0][0])\n",
    "pred = \"yes (tumor)\" if prob >= 0.5 else \"no (no tumor)\"\n",
    "print(f\"Prediction: {pred} | tumor probability = {prob:.3f}\")\n",
    "\n",
    "# Grad-CAM for this image too (optional)\n",
    "heatmap = get_gradcam_heatmap(model, arr, \"conv2\")\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,3,1); plt.imshow(arr[0].squeeze(), cmap=\"gray\"); plt.title(\"Image\"); plt.axis(\"off\")\n",
    "plt.subplot(1,3,2); plt.imshow(heatmap, cmap=\"jet\"); plt.title(\"Grad-CAM\"); plt.axis(\"off\")\n",
    "plt.subplot(1,3,3); \n",
    "overlay = tf.image.resize(tf.expand_dims(heatmap, -1), IMG_SIZE).numpy().squeeze()\n",
    "plt.imshow(arr[0].squeeze(), cmap=\"gray\"); plt.imshow(overlay, cmap=\"jet\", alpha=0.4)\n",
    "plt.title(f\"Overlay\\n{pred} ({prob:.2f})\"); plt.axis(\"off\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff274d1-6652-4e67-8ee7-459b7cfd2f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
